{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input_layer,filters,ksize,strides,padding,name):\n",
    "    \n",
    "    with tf.name_scope(name):\n",
    "        \n",
    "        size_in=input_layer.get_shape().as_list()[-1] # Получаем кол-во каналов\n",
    "        \n",
    "        w=tf.Variable(tf.truncated_normal([ksize[0],ksize[1],size_in,filters],stddev=0.1,name=\"W\"))\n",
    "        \n",
    "        b=tf.Variable(tf.constant(0.1,shape=[filters]),name=\"B\")\n",
    "        \n",
    "        conv=tf.nn.conv2d(input_layer,w,strides=strides,padding=padding)\n",
    "        \n",
    "        act=tf.nn.relu(conv + b)\n",
    "        \n",
    "        tf.summary.histogram(\"weights\",w)\n",
    "        \n",
    "        tf.summary.histogram(\"biases\",b)\n",
    "        \n",
    "        tf.summary.histogram(\"activations\",act)\n",
    "        \n",
    "        return act \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSD_Model(learning_rate,arr):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    sess=tf.Session()\n",
    "    \n",
    "    x=tf.placeholder(tf.float32,shape=[None,300,300,3],name=\"x\")\n",
    "    x_image=tf.reshape(x,[-1,300,300,3])\n",
    "    tf.summary.image('input',x_image,3)\n",
    "    \n",
    "    #y PLACEHOLDER не обозначен\n",
    "    \n",
    "    conv1_1=conv_layer(input_layer=x_image,filters=64,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv1')\n",
    "    \n",
    "    print('conv1_1 shape : {}'.format(conv1_1.get_shape().as_list()))\n",
    "    \n",
    "    conv1_2=conv_layer(input_layer=conv1_1,filters=64,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv2')\n",
    "    \n",
    "    print('conv1_2 shape : {}'.format(conv1_2.get_shape().as_list()))\n",
    "    \n",
    "    pool1=tf.nn.max_pool(conv1_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    print('pool1 shape : {}'.format(pool1.get_shape().as_list()))\n",
    "    \n",
    "    conv2_1=conv_layer(input_layer=pool1,filters=128,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv2_1')\n",
    "    \n",
    "    print('conv2_1 shape : {}'.format(conv2_1.get_shape().as_list()))\n",
    "    \n",
    "    conv2_2=conv_layer(input_layer=conv2_1,filters=128,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv2_2')\n",
    "    \n",
    "    print('conv2_2 shape : {}'.format(conv2_2.get_shape().as_list()))\n",
    "    \n",
    "    pool2=tf.nn.max_pool(conv2_2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    print('pool2 shape : {}'.format(pool2.get_shape().as_list()))\n",
    "    \n",
    "    conv3_1=conv_layer(input_layer=pool2,filters=256,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv3_1')\n",
    "    \n",
    "    print('conv3_1 shape : {}'.format(conv3_1.get_shape().as_list()))\n",
    "    \n",
    "    conv3_2=conv_layer(input_layer=conv3_1,filters=256,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv3_2')\n",
    "    \n",
    "    print('conv3_2 shape : {}'.format(conv3_2.get_shape().as_list()))\n",
    "    \n",
    "    conv3_3=conv_layer(input_layer=conv3_2,filters=256,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv3_3')\n",
    "    \n",
    "    print('conv3_3 shape : {}'.format(conv3_3.get_shape().as_list()))\n",
    "    \n",
    "    pool3=tf.nn.max_pool(conv3_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    print('pool3 shape : {}'.format(pool3.get_shape().as_list()))\n",
    "    \n",
    "    \n",
    "    conv4_1=conv_layer(input_layer=pool3,filters=512,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv4_1')\n",
    "    \n",
    "    print('conv4_1 shape : {}'.format(conv4_1.get_shape().as_list()))\n",
    "    \n",
    "    conv4_2=conv_layer(input_layer=conv4_1,filters=512,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv4_2')\n",
    "    \n",
    "    print('conv4_2 shape : {}'.format(conv4_2.get_shape().as_list()))\n",
    "    \n",
    "    conv4_3=conv_layer(input_layer=conv4_2,filters=512,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv4_3')\n",
    "    \n",
    "    print('conv4_3 shape : {}'.format(conv4_3.get_shape().as_list()))\n",
    "    \n",
    "    pool4=tf.nn.max_pool(conv4_3,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    print('pool4 shape : {}'.format(pool4.get_shape().as_list()))\n",
    "    \n",
    "    \n",
    "    conv5_1=conv_layer(input_layer=pool4,filters=512,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv5_1')\n",
    "    \n",
    "    print('conv5_1 shape : {}'.format(conv5_1.get_shape().as_list()))\n",
    "    \n",
    "    conv5_2=conv_layer(input_layer=conv5_1,filters=512,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv5_2')\n",
    "    \n",
    "    print('conv5_2 shape : {}'.format(conv5_2.get_shape().as_list()))\n",
    "    \n",
    "    conv5_3=conv_layer(input_layer=conv5_2,filters=512,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='conv5_3')\n",
    "    \n",
    "    print('conv5_3 shape : {}'.format(conv5_3.get_shape().as_list()))\n",
    "    \n",
    "    pool5=tf.nn.max_pool(conv5_3,ksize=[1,3,3,1],strides=[1,1,1,1],padding='SAME')\n",
    "    \n",
    "    print('pool5 shape : {}'.format(pool5.get_shape().as_list()))\n",
    "\n",
    "    fc6=conv_layer(input_layer=pool5,filters=1024,ksize=[3,3],strides=[1,1,1,1],padding='SAME',name='fc6')\n",
    "    \n",
    "    print('fc6 shape : {}'.format(fc6.get_shape().as_list()))\n",
    "    \n",
    "    fc7=conv_layer(input_layer=fc6,filters=1024,ksize=[1,1],strides=[1,1,1,1],padding='SAME',name='fc7')\n",
    "    \n",
    "    print('fc7 shape : {}'.format(fc7.get_shape().as_list()))\n",
    "    \n",
    "    conv6_1=conv_layer(input_layer=fc7,filters=256,ksize=[1,1],strides=[1,1,1,1],padding='SAME',name='conv6_1')\n",
    "    \n",
    "    print('conv6_1 : {}'.format(conv6_1.get_shape().as_list()))\n",
    "    \n",
    "    conv6_1=tf.pad(conv6_1,[[0,0],[1,1],[1,1],[0,0]],\"CONSTANT\")\n",
    "    \n",
    "    print('conv6_1 pad: {}'.format(conv6_1.get_shape().as_list()))\n",
    "    \n",
    "    conv6_2=conv_layer(input_layer=conv6_1,filters=512,ksize=[3,3],strides=[1,2,2,1],padding='VALID',name='conv6_2')\n",
    "    \n",
    "    print('conv6_2 : {}'.format(conv6_2.get_shape().as_list()))\n",
    "    \n",
    "    conv7_1=conv_layer(input_layer=conv6_2,filters=128,ksize=[1,1],strides=[1,1,1,1],padding='SAME',name='conv7_1')\n",
    "    \n",
    "    print('conv7_1 : {}'.format(conv7_1.get_shape().as_list()))\n",
    "    \n",
    "    conv7_1=tf.pad(conv7_1,[[0,0],[1,1],[1,1],[0,0]],\"CONSTANT\")\n",
    "    \n",
    "    print('conv7_1 pad: {}'.format(conv7_1.get_shape().as_list()))\n",
    "    \n",
    "    conv7_2=conv_layer(input_layer=conv7_1,filters=128,ksize=[3,3],strides=[1,2,2,1],padding='VALID',name='conv7_2')\n",
    "    \n",
    "    print('conv7_2 : {}'.format(conv7_2.get_shape().as_list()))\n",
    "    \n",
    "    conv8_1=conv_layer(input_layer=conv7_2,filters=128,ksize=[1,1],strides=[1,1,1,1],padding='SAME',name='conv8_1')\n",
    "    \n",
    "    print('conv8_1 : {}'.format(conv8_1.get_shape().as_list()))\n",
    "    \n",
    "    conv8_2=conv_layer(input_layer=conv8_1,filters=256,ksize=[3,3],strides=[1,1,1,1],padding='VALID',name='conv8_2')\n",
    "    \n",
    "    print('conv8_2 : {}'.format(conv8_2.get_shape().as_list()))\n",
    "    \n",
    "    conv9_1=conv_layer(input_layer=conv8_2,filters=128,ksize=[1,1],strides=[1,1,1,1],padding='SAME',name='conv9_1')\n",
    "    \n",
    "    print('conv9_1 : {}'.format(conv9_1.get_shape().as_list()))\n",
    "    \n",
    "    conv9_2=conv_layer(input_layer=conv8_2,filters=256,ksize=[3,3],strides=[1,1,1,1],padding='VALID',name='conv9_2')\n",
    "    \n",
    "    print('conv9_2 : {}'.format(conv9_2.get_shape().as_list()))\n",
    "    \n",
    "    # Feed conv4_3 into the L2 normalization layer\n",
    "    conv4_3_norm=tf.nn.l2_normalize(conv4_3,dim=0)\n",
    "    \n",
    "    # We precidt n_classes confidence values for each box, hence the confidence predictors have depth n_boxes * n_classes\n",
    "    # Output shape of the confidence layers: (batch, height, width, n_boxes * n_classes)\n",
    "    \n",
    "    conv4_3_norm_mbox_conf=conv_layer(input_layer=conv4_3_norm,filters=n_boxes[0]*n_classes,ksize=[3,3],padding='SAME',name='conv4_3_norm_mbox_conf')\n",
    "\n",
    "    fc7_mbox_conf=conv_layer(input_layer=fc7,filters=n_boxes[1]*n_classes,ksize=[3,3],padding='SAME',name='fc7_mbox_conf')\n",
    "    \n",
    "    conv6_2_mbox_conf=conv_layer(input_layer=conv6_2,filters=n_boxes[2]*n_classes,ksize=[3,3],padding='SAME',name='conv6_2_mbox_conf')\n",
    "    \n",
    "    conv7_2_mbox_conf=conv_layer(input_layer=conv7_2,filters=n_boxes[3]*n_classes,ksize=[3,3],padding='SAME',name='conv7_2_mbox_conf')\n",
    "    \n",
    "    conv8_2_mbox_conf=conv_layer(input_layer=conv8_2,filters=n_boxes[4]*n_classes,ksize=[3,3],padding='SAME',name='conv8_2_mbox_conf')\n",
    "    \n",
    "    conv9_2_mbox_conf=conv_layer(input_layer=conv9_2,filters=n_boxes[5]*n_classes,ksize=[3,3],padding='SAME',name='conv9_2_mbox_conf')\n",
    "    \n",
    "    # We predict 4 box coordinates for each box, hence the localization predictors have depth n_boxes * 4\n",
    "    # Output shape of the localization layers: (batch, height, width, n_boxes * 4)\n",
    "    \n",
    "    conv4_3_norm_mbox_loc=conv_layer(input_layer=conv4_3_norm,filters=n_boxes[0]*4,ksize=[3,3],padding='SAME',name='conv4_3_norm_mbox_loc')\n",
    "\n",
    "    fc7_mbox_loc=conv_layer(input_layer=fc7,filters=n_boxes[1]*4,ksize=[3,3],padding='SAME',name='fc7_mbox_loc')\n",
    "    \n",
    "    conv6_2_mbox_loc=conv_layer(input_layer=conv6_2,filters=n_boxes[2]*4,ksize=[3,3],padding='SAME',name='conv6_2_mbox_loc')\n",
    "    \n",
    "    conv7_2_mbox_loc=conv_layer(input_layer=conv7_2,filters=n_boxes[3]*4,ksize=[3,3],padding='SAME',name='conv7_2_mbox_loc')\n",
    "    \n",
    "    conv8_2_mbox_loc=conv_layer(input_layer=conv8_2,filters=n_boxes[4]*4,ksize=[3,3],padding='SAME',name='conv8_2_mbox_loc')\n",
    "    \n",
    "    conv9_2_mbox_loc=conv_layer(input_layer=conv9_2,filters=n_boxes[5]*4,ksize=[3,3],padding='SAME',name='conv9_2_mbox_loc')\n",
    "    \n",
    "    ### Generate the anchor boxes\n",
    "\n",
    "    # Output shape of anchors: (batch, height, width, n_boxes, 8)\n",
    "    conv4_3_norm_mbox_priorbox = AnchorBoxes(img_height=img_height,img_width=img_width,this_scale=scales[0],next_scale=scales[1],aspect_ratios=aspect_ratios[0],\n",
    "                                             two_boxes_for_ar1=two_boxes_for_ar1,this_steps=steps[0],this_offsets=offsets[0],clip_boxes=clip_boxes,\n",
    "                                             variances=variances,coords=coords,normalize_coords=normalize_coords).call(conv4_3_norm_mbox_loc)\n",
    "\n",
    "    fc7_mbox_priorbox = AnchorBoxes(img_height=img_height,img_width=img_width,this_scale=scales[1],next_scale=scales[2],aspect_ratios=aspect_ratios[1],\n",
    "                                             two_boxes_for_ar1=two_boxes_for_ar1,this_steps=steps[1],this_offsets=offsets[1],clip_boxes=clip_boxes,\n",
    "                                             variances=variances,coords=coords,normalize_coords=normalize_coords).call(fc7_mbox_loc)\n",
    "\n",
    "    conv6_2_norm_mbox_priorbox = AnchorBoxes(img_height=img_height,img_width=img_width,this_scale=scales[2],next_scale=scales[3],aspect_ratios=aspect_ratios[2],\n",
    "                                         two_boxes_for_ar1=two_boxes_for_ar1,this_steps=steps[2],this_offsets=offsets[2],clip_boxes=clip_boxes,\n",
    "                                         variances=variances,coords=coords,normalize_coords=normalize_coords).call(conv6_2_mbox_loc)\n",
    "\n",
    "    conv7_2_norm_mbox_priorbox = AnchorBoxes(img_height=img_height,img_width=img_width,this_scale=scales[3],next_scale=scales[4],aspect_ratios=aspect_ratios[3],\n",
    "                                         two_boxes_for_ar1=two_boxes_for_ar1,this_steps=steps[3],this_offsets=offsets[3],clip_boxes=clip_boxes,\n",
    "                                         variances=variances,coords=coords,normalize_coords=normalize_coords).call(conv7_2_mbox_loc)\n",
    "\n",
    "    conv8_2_norm_mbox_priorbox = AnchorBoxes(img_height=img_height,img_width=img_width,this_scale=scales[4],next_scale=scales[5],aspect_ratios=aspect_ratios[4],\n",
    "                                     two_boxes_for_ar1=two_boxes_for_ar1,this_steps=steps[4],this_offsets=offsets[4],clip_boxes=clip_boxes,\n",
    "                                     variances=variances,coords=coords,normalize_coords=normalize_coords).call(conv8_2_mbox_loc)\n",
    "\n",
    "    conv9_2_norm_mbox_priorbox = AnchorBoxes(img_height=img_height,img_width=img_width,this_scale=scales[5],next_scale=scales[6],aspect_ratios=aspect_ratios[5],\n",
    "                                     two_boxes_for_ar1=two_boxes_for_ar1,this_steps=steps[5],this_offsets=offsets[5],clip_boxes=clip_boxes,\n",
    "                                     variances=variances,coords=coords,normalize_coords=normalize_coords).call(conv9_2_mbox_loc)\n",
    "\n",
    "    \n",
    "    ### Reshape\n",
    "\n",
    "    # Reshape the class predictions, yielding 3D tensors of shape `(batch, height * width * n_boxes, n_classes)`\n",
    "    # We want the classes isolated in the last axis to perform softmax on them\n",
    "\n",
    "    conv4_3_norm_mbox_conf_reshape = tf.reshape(conv4_3_norm_mbox_conf,[-1,n_classes])\n",
    "    fc7_mbox_conf_reshape = tf.reshape(fc7_mbox_conf,[-1,n_classes])\n",
    "    conv6_2_mbox_conf_reshape = tf.reshape(conv6_2_mbox_conf,[-1,n_classes])\n",
    "    conv7_2_mbox_conf_reshape = tf.reshape(conv7_2_mbox_conf,[-1,n_classes])\n",
    "    conv8_2_mbox_conf_reshape = tf.reshape(conv8_2_mbox_conf,[-1,n_classes])\n",
    "    conv9_2_mbox_conf_reshape = tf.reshape(conv9_2_mbox_conf,[-1,n_classes])\n",
    "\n",
    "    # Reshape the box predictions, yielding 3D tensors of shape `(batch, height * width * n_boxes, 4)`\n",
    "    # We want the four box coordinates isolated in the last axis to compute the smooth L1 loss\n",
    "\n",
    "    conv4_3_norm_mbox_loc_reshape = tf.reshape(conv4_3_norm_mbox_loc,[-1,4])\n",
    "    fc7_mbox_loc_reshape = tf.reshape(fc7_mbox_loc,[-1,4])\n",
    "    conv6_2_mbox_loc_reshape = tf.reshape(conv6_2_mbox_loc,[-1,4])\n",
    "    conv7_2_mbox_loc_reshape = tf.reshape(conv7_2_mbox_loc,[-1,4])\n",
    "    conv8_2_mbox_loc_reshape = tf.reshape(conv8_2_mbox_loc,[-1,4])\n",
    "    conv9_2_mbox_loc_reshape = tf.reshape(conv9_2_mbox_loc,[-1,4])\n",
    "\n",
    "    # Reshape the anchor box tensors, yielding 3D tensors of shape `(batch, height * width * n_boxes, 8)`\n",
    "\n",
    "    conv4_3_norm_mbox_priorbox_reshape = tf.reshape(conv4_3_norm_mbox_priorbox,[-1,8])\n",
    "    fc7_mbox_priorbox_reshape = tf.reshape(fc7_mbox_priorbox,[-1,8])\n",
    "    conv6_2_norm_mbox_priorbox_reshape = tf.reshape(conv6_2_norm_mbox_priorbox,[-1,8])\n",
    "    conv7_2_norm_mbox_priorbox_reshape = tf.reshape(conv7_2_norm_mbox_priorbox,[-1,8])\n",
    "    conv8_2_norm_mbox_priorbox_reshape = tf.reshape(conv8_2_norm_mbox_priorbox,[-1,8])\n",
    "    conv9_2_norm_mbox_priorbox_reshape = tf.reshape(conv9_2_norm_mbox_priorbox,[-1,8])\n",
    "    \n",
    "    ### Concatenate the predictions from the different layers\n",
    "\n",
    "    # Axis 0 (batch) and axis 2 (n_classes or 4, respectively) are identical for all layer predictions,\n",
    "    # so we want to concatenate along axis 1, the number of boxes per layer\n",
    "\n",
    "    # Output shape of `mbox_conf`: (batch, n_boxes_total, n_classes)\n",
    "\n",
    "    print(conv4_3_norm_mbox_conf_reshape.get_shape())\n",
    "    print(fc7_mbox_conf_reshape.get_shape())\n",
    "    print(conv6_2_mbox_conf_reshape.get_shape())\n",
    "    print(conv7_2_mbox_conf_reshape.get_shape())\n",
    "    print(conv8_2_mbox_conf_reshape.get_shape())\n",
    "    print(conv9_2_mbox_conf_reshape.get_shape())\n",
    "\n",
    "\n",
    "    mbox_conf = tf.concat([conv4_3_norm_mbox_conf_reshape,\n",
    "                           fc7_mbox_conf_reshape,\n",
    "                           conv6_2_mbox_conf_reshape,\n",
    "                           conv7_2_mbox_conf_reshape,\n",
    "                           conv8_2_mbox_conf_reshape,\n",
    "                           conv9_2_mbox_conf_reshape],axis=0)\n",
    "\n",
    "    # Output shape of `mbox_loc`: (batch, n_boxes_total, 4)\n",
    "\n",
    "    mbox_loc = tf.concat([conv4_3_norm_mbox_loc_reshape,\n",
    "                          fc7_mbox_loc_reshape,\n",
    "                          conv6_2_mbox_loc_reshape,\n",
    "                          conv7_2_mbox_loc_reshape,\n",
    "                          conv8_2_mbox_loc_reshape,\n",
    "                          conv9_2_mbox_loc_reshape],axis=0)\n",
    "\n",
    "    # Output shape of `mbox_priorbox`: (batch, n_boxes_total, 8)\n",
    "\n",
    "    mbox_priorbox = tf.concat([conv4_3_norm_mbox_priorbox_reshape,\n",
    "                               fc7_mbox_priorbox_reshape,\n",
    "                               conv6_2_norm_mbox_priorbox_reshape,\n",
    "                               conv7_2_norm_mbox_priorbox_reshape,\n",
    "                               conv8_2_norm_mbox_priorbox_reshape,\n",
    "                               conv9_2_norm_mbox_priorbox_reshape],axis=0)\n",
    "\n",
    "    # The box coordinate predictions will go into the loss function just the way they are,\n",
    "    # but for the class predictions, we'll apply a softmax activation layer first\n",
    "\n",
    "    mbox_conf_softmax = tf.nn.softmax(mbox_conf)\n",
    "\n",
    "    # Concatenate the class and box predictions and the anchors to one large predictions vector\n",
    "    # Output shape of `predictions`: (batch, n_boxes_total, n_classes + 4 + 8)\n",
    "\n",
    "    predictions = tf.concat([mbox_conf_softmax, mbox_loc, mbox_priorbox],axis=-1)\n",
    "\n",
    "    print(predictions.get_shape())\n",
    "    \n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    sess.run(pool1,feed_dict={x:arr})\n",
    "    \n",
    "    return pool1.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_1 shape : [None, 300, 300, 64]\n",
      "conv1_2 shape : [None, 300, 300, 64]\n",
      "pool1 shape : [None, 150, 150, 64]\n",
      "conv2_1 shape : [None, 150, 150, 128]\n",
      "conv2_2 shape : [None, 150, 150, 128]\n",
      "pool2 shape : [None, 75, 75, 128]\n",
      "conv3_1 shape : [None, 75, 75, 256]\n",
      "conv3_2 shape : [None, 75, 75, 256]\n",
      "conv3_3 shape : [None, 75, 75, 256]\n",
      "pool3 shape : [None, 38, 38, 256]\n",
      "conv4_1 shape : [None, 38, 38, 512]\n",
      "conv4_2 shape : [None, 38, 38, 512]\n",
      "conv4_3 shape : [None, 38, 38, 512]\n",
      "pool4 shape : [None, 19, 19, 512]\n",
      "conv5_1 shape : [None, 19, 19, 512]\n",
      "conv5_2 shape : [None, 19, 19, 512]\n",
      "conv5_3 shape : [None, 19, 19, 512]\n",
      "pool5 shape : [None, 19, 19, 512]\n",
      "fc6 shape : [None, 19, 19, 1024]\n",
      "fc7 shape : [None, 19, 19, 1024]\n",
      "conv6_1 : [None, 19, 19, 256]\n",
      "conv6_1 pad: [None, 21, 21, 256]\n",
      "conv6_2 : [None, 10, 10, 512]\n",
      "conv7_1 : [None, 10, 10, 128]\n",
      "conv7_1 pad: [None, 12, 12, 128]\n",
      "conv7_2 : [None, 5, 5, 128]\n",
      "conv8_1 : [None, 5, 5, 128]\n",
      "conv8_2 : [None, 3, 3, 256]\n",
      "conv9_1 : [None, 3, 3, 128]\n",
      "conv9_2 : [None, 1, 1, 256]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(150), Dimension(150), Dimension(64)])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSD_Model(learning_rate=1E-3,arr=test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.random.randint(low=0,high=255,size=270000).reshape((300,300,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=np.expand_dims(test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 300, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
